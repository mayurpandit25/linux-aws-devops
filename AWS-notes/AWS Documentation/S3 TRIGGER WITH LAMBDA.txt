**S3 TRIGGER WITH LAMBDA**

1.create a role
    1.type----------aws service
    2.use case------lambda
    3.policy--------dynamoDBfullAccess
    4.role name-----role-for-lambda


2.create a lambda function
    1.author from scratch
    2.name---------lambda
    3.runtime------python3.7
    4.advanced setting---role---existing role---(role-for-lambda)


3.create a s3 bucket
    1.my-s2-bucket
    2.give them a public access


4.go to lambda
    1.paste the code on function

        import boto3
        from uuid import uuid4
        def lambda_handler(event, context):
            s3 = boto3.client("s3")
            dynamodb = boto3.resource('dynamodb')
            for record in event['Records']:
                bucket_name = record['s3']['bucket']['name']
                object_key = record['s3']['object']['key']
                size = record['s3']['object'].get('size', -1)
                event_name = record ['eventName']
                event_time = record['eventTime']
                dynamoTable = dynamodb.Table('newtable')
                dynamoTable.put_item(
                Item={'unique': str(uuid4()), 'Bucket': bucket_name, 'Object': object_key,'Size': size, 'Event': event_name, 'EventTime': event_time})

    2.and deploy the code


5.then trigger the s3 bucket
    1.click on trigger
    2.search---s3
    3.bucket---my-s2-bucket
    4.event----all-object-create-event
    5.enable trigger
    6.create a trigger


6.go to dynamoDB
    1.create a table
          1.table-name----newtable
          2.partion key---unique
          3.create 


7.go to s3 bucket
    1.click on bucket
    2.add objects in the buckets


8.go to dynamodb
    1.click on tables
    2.click on newtable
    3.click on explore item

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
